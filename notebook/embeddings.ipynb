{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cef6f91",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0772259",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Automatically detect the repo root (parent of notebook folder)\n",
    "repo_root = Path().resolve().parent  # if notebook is in 'notebooks/' folder\n",
    "sys.path.append(str(repo_root))\n",
    "\n",
    "from config.config import get_environment\n",
    "\n",
    "from config.config import data_import_json, data_export_json, data_import_pandas, data_export_pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3179b99b",
   "metadata": {},
   "source": [
    "## ENV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63759bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV = get_environment(\n",
    "    env_path=\"../environments\",\n",
    "    env_name=\"env.json\"\n",
    ")\n",
    "\n",
    "# content_date = datetime.now().date() + timedelta(days=0)\n",
    "content_date = ENV['CONTENT_DATE']\n",
    "website = ENV['SOURCE']['NAME']\n",
    "version = ENV['VERSION']\n",
    "\n",
    "EMB_MODEL = ENV['EMBEDDING']['OPENAI']['MODEL']\n",
    "EMB_API_KEY = ENV['EMBEDDING']['OPENAI']['API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c945a9a",
   "metadata": {},
   "source": [
    "## Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa06183b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_input = data_import_pandas(\n",
    "    website=website,\n",
    "    content_date=content_date,\n",
    "    version=version,\n",
    "    folder_name='cleaning',\n",
    "    additional_info='mapping'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118eb0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_input(\n",
    "        df_input: pd.DataFrame\n",
    "    ):\n",
    "\n",
    "    df_embed = df_input.copy(deep=True)\n",
    "    df_embed = df_embed[df_embed['level'].notna()]\n",
    "    df_embed = df_embed[df_embed['response_cleaning'].astype(str) != '[]']\n",
    "    df_embed = df_embed[~df_embed['qualification'].str.contains('linkcopy link')]\n",
    "    df_embed = df_embed[df_embed['qualification'].fillna('').astype(str) != '']\n",
    "    df_embed = df_embed[df_embed['qualification'].apply(len) > 50].reset_index(drop=True)\n",
    "\n",
    "    return df_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105f0931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter non empty target (level) and preprocess\n",
    "df_embed = filter_input(\n",
    "    df_input=df_input\n",
    ")\n",
    "\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm\n",
    "from openai import OpenAI\n",
    "\n",
    "# 3b. Embeddings for qualification (batched)\n",
    "\n",
    "def get_embeddings_batch(\n",
    "        input_list: list,\n",
    "        api_key: str,\n",
    "        model: str=\"text-embedding-3-small\",\n",
    "        range_input: int=50,\n",
    "        sleep_sec: float=0.5\n",
    "    ):\n",
    "\n",
    "    client = OpenAI(api_key=api_key)\n",
    "\n",
    "    embeddings = []\n",
    "    for i in tqdm(range(0, len(input_list), range_input), desc=\"Embedding\"):\n",
    "        batch_texts = input_list[i:i+range_input]\n",
    "\n",
    "        retry = 1\n",
    "        while True:\n",
    "            try:            \n",
    "                response = client.embeddings.create(\n",
    "                    model=model,\n",
    "                    input=batch_texts\n",
    "                )\n",
    "\n",
    "                # response.usage.prompt_tokens\n",
    "                # response.usage.total_tokens\n",
    "\n",
    "                batch_embeddings = [item.embedding for item in response.data]\n",
    "                embeddings.extend(batch_embeddings)\n",
    "                break\n",
    "\n",
    "            except Exception as e:\n",
    "                if retry > 3:\n",
    "                    raise e\n",
    "                else:\n",
    "                    retry += 1\n",
    "                    print(e)\n",
    "\n",
    "            time.sleep(sleep_sec)\n",
    "    return embeddings\n",
    "\n",
    "X_qual_embed = get_embeddings_batch(\n",
    "    input_list=df_embed['qualification'].tolist(),\n",
    "    api_key=EMB_API_KEY,\n",
    "    model=EMB_MODEL\n",
    ")\n",
    "df_embed['qualification_embedding'] = [list(vec) for vec in X_qual_embed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5d8535",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_export_pandas(\n",
    "    df_output=df_embed,\n",
    "    website=website,\n",
    "    content_date=content_date,\n",
    "    version=version,\n",
    "    folder_name='embeddings',\n",
    "    additional_info='embeddings',\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
